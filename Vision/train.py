from ultralytics import RTDETR
import torch
from pathlib import Path

def train():
    # 1. Configuraci√≥n B√°sica
    # Ajusta el batch seg√∫n tu VRAM. 
    # RT-DETR es pesado. Si tienes error de memoria, baja BATCH_SIZE a 4 o 2.
    BATCH_SIZE = 8 
    EPOCHS = 1           # BDD es grande, 50 √©pocas es un buen inicio
    IMG_SIZE = 640        # Tama√±o est√°ndar
    DEVICE = '0' if torch.cuda.is_available() else 'cpu'

    print(f"üöÄ Iniciando entrenamiento en {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}...")

    # 2. Cargar Modelo Pre-entrenado
    # Usamos los pesos 'l' (Large) que ya tienes. 
    # Al cargar un .pt existente, Ultralytics hace fine-tuning autom√°ticamente.
    model_path = "Vision/models/rtdetr-l.pt"
    
    # Si no encuentra el modelo local, descargar√° el oficial autom√°ticamente
    model = RTDETR(model_path) 

    # 3. Ejecutar Entrenamiento
    results = model.train(
        data="Vision/config/bdd_det_train.yaml",
        epochs=EPOCHS,
        imgsz=IMG_SIZE,
        batch=BATCH_SIZE,
        device=DEVICE,
        
        # Hiperpar√°metros importantes para Fine-Tuning
        lr0=0.0001,       # Learning rate inicial bajo para no romper lo pre-entrenado
        optimizer='AdamW', # Recomendado para Transformers
        
        # Guardado
        project="Vision/runs/train",
        name="rtdetr_bdd_finetune",
        exist_ok=True,    # Sobreescribir si existe la carpeta (cuidado)
        
        # Visualizaci√≥n
        plots=True        # Genera gr√°ficas de p√©rdida y mAP
    )
    
    print("‚úÖ Entrenamiento finalizado.")
    print(f"   Mejor modelo guardado en: Vision/runs/train/rtdetr_bdd_finetune/weights/best.pt")

if __name__ == '__main__':
    train()